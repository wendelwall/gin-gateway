server:
  port: 9000
spring:
  redis:
    host: localhost
    password: sqlzyydxe
    database: 0
    port: 6379
  kafka:
    # kafka服务器地址(可以多个)
    bootstrap-servers: 127.0.0.1:9092
    consumer:
      # 指定一个默认的组名
      group-id: kafka2
      # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
      # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
      auto-offset-reset: earliest
      # key/value的反序列化
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer


  cloud:
    gateway:
      routes:
      - id: api-route
        # lb代表从注册中心获取服务
        uri: lb://api-service
        predicates:
        # 转发该路径
        - Path=/api/**
#        filters:
#        # 是否去掉前缀（第一个目录）
#        - StripPrefix=1
      - id: h5-route
        # lb代表从注册中心获取服务
        uri: lb://h5-service
        predicates:
        # 转发该路径
        - Path=/h5/**

# eurker
eureka:
  instance:
    prefer-ip-address: true
    instance-id: ${spring.application.name}:${server.port}:${random.value}
  client:
    enabled: true
    service-url:
      defaultZone: http://user:password@localhost:8761/eureka/
    register-with-eureka: true
    fetch-registry: true

# LOGGING
logging:
  level:
    root: INFO
#    org.springframework.security: DEBUG
#    org.springframework.cloud.netflix: INFO
#    com.netflix.zuul: INFO
    com.riskeys: DEBUG

#开启actuator管理api，后面要关闭
#management:
#  endpoints:
#    web:
#      exposure:
#        include: "*"